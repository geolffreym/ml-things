{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COL_NAMES': ['label', 'data'],\n",
       " 'DESCR': 'mldata.org dataset: mnist-original',\n",
       " 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'target': array([ 0.,  0.,  0., ...,  9.,  9.,  9.])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependent and Independent var\n",
    "# Input - output\n",
    "# Features - Label\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion for class 0 => 0.09861428571428571\n",
      "Count for class 0 => 6903\n",
      "Proportion for class 1 => 0.11252857142857142\n",
      "Count for class 1 => 7877\n",
      "Proportion for class 2 => 0.09985714285714285\n",
      "Count for class 2 => 6990\n",
      "Proportion for class 3 => 0.10201428571428571\n",
      "Count for class 3 => 7141\n",
      "Proportion for class 4 => 0.09748571428571429\n",
      "Count for class 4 => 6824\n",
      "Proportion for class 5 => 0.09018571428571429\n",
      "Count for class 5 => 6313\n",
      "Proportion for class 6 => 0.09822857142857143\n",
      "Count for class 6 => 6876\n",
      "Proportion for class 7 => 0.10418571428571428\n",
      "Count for class 7 => 7293\n",
      "Proportion for class 8 => 0.0975\n",
      "Count for class 8 => 6825\n",
      "Proportion for class 9 => 0.0994\n",
      "Count for class 9 => 6958\n"
     ]
    }
   ],
   "source": [
    "# Basic stats\n",
    "# Check balancing for classification\n",
    "# Is accuracy reliable?\n",
    "# La descompensacion de los datos genera un mal calculo de la exactitud (accuracy)\n",
    "# ex: 100TP + 1200TN / 100TP + 1200TN + 50FP + 50FN = 0.89\n",
    "from collections import Counter\n",
    "\n",
    "n = X.shape[0]\n",
    "count = Counter(y.tolist())\n",
    "\n",
    "# Check proportions to lookup balance in classes \n",
    "for idx, val in dict(count).items():\n",
    "    print(\"Proportion for class\", int(idx), \"=>\", val / n)\n",
    "    print(\"Count for class\", int(idx), \"=>\", val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f92bdddac18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def plot_digit(index):\n",
    "    some_digit = X[index]\n",
    "    some_digit = some_digit.reshape(28,28)\n",
    "    plt.imshow(some_digit, cmap=matplotlib.cm.binary)\n",
    "    plt.show()\n",
    "    \n",
    "plot_digit(36000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "print(y[36000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, learning_curve, StratifiedKFold, KFold, \\\n",
    "    validation_curve, cross_val_score\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.astype(np.float64))\n",
    "X_test = scaler.fit_transform(X_test.astype(np.float64))\n",
    "X_train                               \n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def scorer(pred, classif): \n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    cross_val=np.mean(cross_val_score(\n",
    "        classif, X_train, y_train, cv=cv, scoring=make_scorer(f1_score, average='macro')\n",
    "    ))\n",
    "    \n",
    "    \n",
    "    print('CrossVal Acc:', cross_val)\n",
    "    print('F1 Score:', f1_score(y_test, pred, average='macro'))\n",
    "\n",
    "\n",
    "def fit_predict(classif):\n",
    "    import time\n",
    "    before = time.time()\n",
    "    \n",
    "    print('Model:', classif.__class__.__name__)   \n",
    "    classif = OneVsRestClassifier(classif)\n",
    "    classif.fit(X_train, y_train)\n",
    "    train_time =  time.time() - before\n",
    "    \n",
    "    y_pred = classif.predict(X_train)\n",
    "    print('Train Acc: ',accuracy_score(y_train, y_pred))\n",
    "    y_pred = classif.predict(X_test)\n",
    "    print('Test Acc: ',accuracy_score(y_test, y_pred))\n",
    "    pred_time = time.time() - before\n",
    "    \n",
    "    scorer(y_pred, classif)\n",
    "    val_time= time.time() - before\n",
    "    \n",
    "    print('Train Time:', train_time)\n",
    "    print('Pred Time:', pred_time)\n",
    "    print('Validation Time:', val_time, '\\n', '\\n')\n",
    "\n",
    "    return classif\n",
    "    \n",
    "def fit_grid_predict(classif, params, scoring='accuracy'):\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    import time\n",
    "    before = time.time()\n",
    "    \n",
    "    print('Model:', classif.__class__.__name__)\n",
    "    gs = GridSearchCV(classif, params, scoring, cv=cv)\n",
    "    gs.fit(X_train, y_train)\n",
    "    train_time =  time.time() - before\n",
    "    \n",
    "    y_pred = gs.predict(X_train)\n",
    "    y_pred = gs.predict(X_test)\n",
    "    pred_time = time.time() - before\n",
    "    \n",
    "    print('Train Time:', train_time)\n",
    "    print('Pred Time:', pred_time)\n",
    "    print('Best Score:', gs.best_score_, '\\n', '\\n')\n",
    "\n",
    "    return gs.best_estimator_\n",
    "    \n",
    "def complex_curve(estimator, **kwargs):\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    # MODEL COMPLEX SCORE\n",
    "    # Calculate the training and testing scores\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        estimator, X, y, cv=cv, **kwargs\n",
    "    )\n",
    "    \n",
    "     # Find the mean and standard deviation for smoothing\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(7, 5))\n",
    "    \n",
    "    plt.title(estimator.__class__.__name__)\n",
    "    plt.plot(kwargs['param_range'], train_mean, 'o-', color='r', label='Training Score')\n",
    "    plt.plot(kwargs['param_range'], test_mean, 'o-', color='g', label='Validation Score')\n",
    "    \n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xlabel(kwargs['param_name'])\n",
    "    plt.ylabel('score')\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.show()\n",
    "    \n",
    "    # For each depth\n",
    "    for x, k in enumerate(train_scores):\n",
    "        print(kwargs['param_name'], kwargs['param_range'][x])\n",
    "        print('score train:', np.mean(train_scores[x]))\n",
    "        print('score test:', np.mean(test_scores[x]))\n",
    "        \n",
    "def learn_curve(estimator, **kwargs):\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    # Generate the training set sizes increasing by 50\n",
    "    train_sizes = np.rint(np.linspace(1, X.shape[0] * 0.8 - 1, 9)).astype(int)\n",
    "\n",
    "    # Calculate the training and testing scores\n",
    "    sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, train_sizes=train_sizes,\n",
    "        scoring=make_scorer(f1_score, average='macro')\n",
    "    )\n",
    "\n",
    "    # Find the mean and standard deviation for smoothing\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "    # Subplot the learning curve\n",
    "    ax = fig.add_subplot(2, 2, k + 1)\n",
    "    ax.plot(sizes, train_mean, 'o-', color='r', label='Training Score')\n",
    "    ax.plot(sizes, test_mean, 'o-', color='g', label='Testing Score')\n",
    "\n",
    "    # Labels\n",
    "    ax.set_title('%s = %s' % (kwargs['param_name'],p))\n",
    "    ax.set_xlabel('Number of Training Points')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_xlim([0, X.shape[0] * 0.8])\n",
    "    ax.set_ylim([-0.05, 1.05])\n",
    "    \n",
    "    # Visual aesthetics\n",
    "\n",
    "    fig.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check learning curve and comple\n",
    "#complex_curve(SGDClassifier(), param_name='eta0', param_range=[0.2,0.5,0.8,0.9])\n",
    "#complex_curve(SGDClassifier(), param_name='n_iter', param_range=[10,20,30,40,50,60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier\n",
      "Train Acc:  0.883767857143\n",
      "Test Acc:  0.874642857143\n",
      "CrossVal Acc: 0.871874965932\n",
      "F1 Score: 0.873168593134\n",
      "Train Time: 11.984313011169434\n",
      "Pred Time: 13.896707534790039\n",
      "Validation Time: 146.7354917526245 \n",
      " \n",
      "\n",
      "Model: SGDClassifier\n",
      "Train Acc:  0.918303571429\n",
      "Test Acc:  0.910785714286\n",
      "CrossVal Acc: 0.910302115148\n",
      "F1 Score: 0.909746191757\n",
      "Train Time: 3.541851282119751\n",
      "Pred Time: 4.248298406600952\n",
      "Validation Time: 39.40767216682434 \n",
      " \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "fit_predict(RandomForestClassifier(max_depth=5, n_estimators=10))\n",
    "fit_predict(SGDClassifier(random_state=42))\n",
    "#fit_predict(DecisionTreeClassifier(max_depth=5))\n",
    "#fit_predict(LogisticRegression(multi_class='multinomial', solver='lbfgs'))\n",
    "#fit_predict(GaussianNB())\n",
    "# fit_predict(KNeighborsClassifier())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SGDClassifier\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# logit = fit_grid_predict(LogisticRegression(), {'multi_class':['multinomial'], 'solver':['lbfgs','newton-cg','saga']})                                                \n",
    "sgd = fit_grid_predict(\n",
    "    SGDClassifier(), \n",
    "    [\n",
    "        {'penalty':['l1', 'l2', 'elasticnet'], \n",
    "         'learning_rate':['constant','optimal'], \n",
    "         'eta0':[0.2,0.5,0.8,0.9]\n",
    "        }, \n",
    "        { \n",
    "         'learning_rate':['constant','optimal'], \n",
    "         'eta0':[0.2,0.5,0.8,0.9],\n",
    "         'n_iter':[10,20,30,40,50,60]\n",
    "            \n",
    "        }\n",
    "    ], make_scorer(f1_score, average='macro')\n",
    ")  \n",
    "\n",
    "sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn_curve(sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_ = PolynomialFeatures(degree=2)\n",
    "poly_x = poly_.fit_transform(X)\n",
    "poly_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "# joblib.dump(forest, 'forest_classif.joblib') \n",
    "joblib.dump(sgd, 'sgd_classif.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#SGD estimator Choosen => best time training, best score\n",
    "y_pred = sgd.predict(X_test)\n",
    "con_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.matshow(con_matrix, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import PIL.Image as Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from PIL import Image\n",
    "#scaler = StandardScaler()\n",
    "#print(scaler.fit_transform(X[20000].astype(np.float64)))\n",
    "#print(X[20000].reshape(28,28).shape)\n",
    "# for x in np.arange(0, 70000, 10000):\n",
    "#     plot_digit(x)\n",
    "#     print(\"Number predictes\",sgd.predict([scaler.fit_transform(X[x].astype(np.float64))]))\n",
    "\n",
    "img = Image.open('number_five.jpg')\n",
    "img = img.convert('L')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#print(img.shape)\n",
    "\n",
    "plt.imshow(img, cmap=matplotlib.cm.binary)\n",
    "plt.show()\n",
    "plt.imshow(X[20000].reshape(28,28), cmap=matplotlib.cm.binary)\n",
    "plt.show()\n",
    "# # print(x.shape)\n",
    "# # print(X_train.reshape(24,24).shape)\n",
    "# my_y_pred = scaler.fit_transform(img.astype(np.float64))\n",
    "#sgd.predict([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
